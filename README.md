# Personal Academic Web Page
This is my personal academic web page. My research interests contain Spiking Neural Network, neurorobotics, event-based cameras, Brain-based visual learning, Active Visual Learning, etc.

## Personal Blog
https://www.bluenote.top

## Previous Projects

### "Miro-CV-System"
This is my dissertation project when I was in the University of Sheffield in 2019. All codes are open sourced, you can read more details from my [repository](https://github.com/LiZheng1997/MiRo-CV-System).

### "Follow Me"
This project's objective is implementing a visual tracking and control system to satisfy customer's requirments(Following trucks, pedestrians and drones). Finally, I used a gimbal camera and a PixKit chassis to achieve a robust visual tracking-by-detection and control system. This project sucessfully helps that customer to do further research based on it, more details are released on my [repository](https://github.com/LiZheng1997/Follow-Me).

### "POSP"
POSP is a project for Picking Out Single Package on a long conveyor belt. This algorithm must work with a Depth Camear, like Realsense D415/D435(I used a D415 in this project). All codes can be accessed from my [repository](https://github.com/LiZheng1997/POSP).

### "RoboBus"
The [Robobus](https://www.pixmoving.com/robobus) is a autonoumous shuttle bus which designed for urban area. I mainly hold the part of whole perception framework, more details can be accessed from my [repository](https://github.com/LiZheng1997/Robobus).

### "Sweeping Robots"
Sweeping robots is an autonomous mobile robot for cleaning road surface. I mainly hold the part of trash detection and obstacle segmentation for avoidance, road curb detection module as well. [repository](https://github.com/LiZheng1997/Sweeping-Robots).


### End-to-End Robot Control based on Events
This end-to-end robot control project is similar with my miro-cv-system project, both of them are using a end-to-end paradigm to control a mobile robots with differential base. However, this project is based on event cameras and implemented with a Spiking Neural Network rather than ANN. More details can be found on my [academic page](https://neuronsvision.com/projects/Event_based_Robot_Control_project/) and [repository](https://github.com/Bluet-NeuroRobotics/Training-Neural-Networks-for-Event-Based-End-to-End-Robot-Control).


### Neurorobotics using Nengo




## Research Experience

### Teach & Repeat Visual Navigation using a Jaguar Robot
An internship with Dr Li Sun in the University of Sheffield about autonomous mobile robots (a Jaguar robot). [Demo](https://v.youku.com/v_show/id_XNDUyMDIyMzU5Ng==.html?spm=a2hzp.8253869.0.0)


## Research & Development works

### SNN with using Event Cameras Streams
Doing initial research and development works in Spiking Neural Network for the perception module of
autonomous robots through using event cameras in **low-light** environments, especially for object
detection.

### A Perception module for KUKA Robotic arms with 3D structured-light stereo cameras
Doing research and development works in the perception module of a KUKA robotic arm project, which
includes doing a survey about the comparison of different **3D structured-light cameras**; designing a solution of collecting the detailed 3D point cloud data for aluminium material; and doing research about how to calculate the physical error between the aluminium product’s point cloud data and the CAD prototype ground truth data.

### A Perception module for sweeping robots with a ZED stereo camera
Doing research and development works in the perception module of sweeping robots, which includes a
trash detection and a segmentation module; road curb detection module. Achieving the design and
solution of mounting a stereo camera detection module on a sweeping robot;  doing research
about data augmentation in object detection research field; and developing a online website for annotating 2D and 3D objects.

### A Perception module of autoware full stack AD framework
Doing research and development works in the perception module based on the framework of Autoware.ai/Autoware.tierIV and Autoware.universe, and finally these works finally formed into a standard released version for customers.

### A Perception module of autonomous shuttle bus
Doing research and development works in the perception module of a Robobus project, which includes
deploying a joint calibration method for cameras and LiDARs; doing research about the comparison of
different vehicle specification level cameras; designing a solution of mounting various cameras for
robots’ perception modules; doing tests about time synchronisation on hardware-level; doing research
about multi-camera BEV perception paradigms for 3D detection modules and doing research about
multi-modal sensor fusion algorithms.


## Patents

A Chinese Invention [Patent](http://epub.cnipa.gov.cn/patent/CN116630374A) Public Patent NO: CN116630374A, Title: 目标对象的视觉跟踪方法、装置、存储介质及设备(A Visual tracking method, device, storage medium and equipment for target object).

## Publications
